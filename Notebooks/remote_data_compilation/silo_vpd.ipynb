{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9MJocir9tJU"
   },
   "source": [
    "# Start\n",
    "\n",
    "\n",
    "This script prepares vapor pressure deficit (VPD) data from SILO and matches it with VPD from field observations for subsequent analysis.\n",
    "\n",
    "\n",
    "ðŸ“„ **What this script does**\n",
    "1. Loads cleaned field data with topography â€” for example, output from `Nick_phd_data_complilation.ipynb`.\n",
    "2. Downloads **SILO data** for the grid cells closest to the field sites, spanning from the first day to one day after the last day of the field observations.\n",
    "3. Find the field observations with the highest and lowest temperature between 9am to 9am of each day and put them separately in `df_max_temp` and `df_min_temp`. When there are multiple observations with the highest or lowest temperatures, the ones with the lowest RH are selected.\n",
    "4. Matches SILO temperature and RH values to the field observations in `df_max_temp` and `df_min_temp` based on the nearest SILO grid cell and `silo_observation_date`.\n",
    "5. For both `df_max_temp` and `df_min_temp`, calculates **VPD** (vapor pressure deficit) from the matched SILO temperature and RH.\n",
    "6. Saves the combined field and SILO data as `silo_max_temp.csv` and `silo_min_temp.csv` in the `output/csv` folder.\n",
    "\n",
    "\n",
    "âš ï¸ **Important notes**\n",
    "* Before running the script, set all variables in the **first cell**, and delete the **second cell** if not using a Google Colab environment.  \n",
    "  *(The script was developed for use in Google Colab and has not been tested outside of it.)*\n",
    "* The **first and last observation dates** of each site are **disregarded** because there is no temperature data for the whole day for those dates.\n",
    "* Obsevations with timestamps between 8.59 am of 1 April 2020 to 9.00 am of 2 April 202 have `silo_observation_date` as 2 April 2020.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGkmuT6BVk2I"
   },
   "outputs": [],
   "source": [
    "input_file_name = 'in-situ_topography_phd.csv'\n",
    "max_temp_output_file_name = 'silo_max_temp_vpd_phd.csv'\n",
    "min_temp_output_file_name = 'silo_min_temp_vpd_phd.csv'\n",
    "\n",
    "download_silo_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWAPFPlBVr4n",
    "outputId": "167b1838-aac4-45bd-d7a8-dab3e140e219"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from Utils.vpd import calculate_vpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_9a1Y7no1QX"
   },
   "source": [
    "# Loading in-situ and remote data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "5lu9eKTyTW92",
    "outputId": "0a9387b5-e1bd-4534-eb44-9d0eafde3eaf"
   },
   "outputs": [],
   "source": [
    "# Load in-situ_topography.csv as the main df\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"..\", \"..\", \"output\", \"csv\", input_file_name))\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "first_date, day_after_last_date = min(df['Datetime']).strftime(\"%Y%m%d\"), (max(df['Datetime']) + pd.Timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "print(\"First date: \", first_date, \", One day after the last date: \", day_after_last_date)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUfZFtpm0NZs",
    "outputId": "8e376d6d-d4a6-4f7a-98e1-67089b50aac1"
   },
   "outputs": [],
   "source": [
    "# Load silo data\n",
    "\n",
    "def nearest_silo_cell(x, y):\n",
    "    return (round(round(x / 0.05) * 0.05, 3), round(round(y / 0.05) * 0.05, 3))\n",
    "\n",
    "# Make a list of locations of all sites and reduce it to silo grid cell locations\n",
    "df['silo_X'] = df.apply(lambda row: nearest_silo_cell(row['X'], row['Y'])[0], axis=1)\n",
    "df['silo_Y'] = df.apply(lambda row: nearest_silo_cell(row['X'], row['Y'])[1], axis=1)\n",
    "silo_cell_locations_list = list(set((x, y) for x, y in df[['silo_X', 'silo_Y']].values))\n",
    "print(\"silo_cell_locations_list: \", silo_cell_locations_list)\n",
    "\n",
    "# Use Python loop and curl to download all silo data\n",
    "silo_data_dir = os.path.join(\"..\", \"..\", \"Data\", \"silo\")\n",
    "if download_silo_data:\n",
    "    os.makedirs(silo_data_dir, exist_ok=True)\n",
    "    for x, y in silo_cell_locations_list:\n",
    "        output_file_path = os.path.join(silo_data_dir, f\"silo_data_{x}_{y}.csv\")\n",
    "        url = f\"https://www.longpaddock.qld.gov.au/cgi-bin/silo/DataDrillDataset.php?lat={y}&lon={x}&format=csv&start={first_date}&finish={day_after_last_date}&username=noemail@net.com&dataset=Official&comment=xnhg\"\n",
    "        print(f\"Downloading {url} to {output_file_path}\")\n",
    "        !curl -L \"{url}\" -o \"{output_file_path}\" -C -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UT6mFyh-PmBY"
   },
   "source": [
    "# Combining in-situ and remote data into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "giSrzedjEA5e",
    "outputId": "57444558-8689-4364-b5bb-0cd21b55915a"
   },
   "outputs": [],
   "source": [
    "# Find in-situ data's hottest and coldest observation of each day\n",
    "\n",
    "# Assign silo_observation_date to each observation\n",
    "mask = (df['Datetime'].dt.hour > 9) | ((df['Datetime'].dt.hour == 9) & (df['Datetime'].dt.minute > 0))\n",
    "df.loc[mask, 'silo_observation_date'] = df.loc[mask, 'Datetime'] + pd.Timedelta(days=1)\n",
    "df.loc[~mask, 'silo_observation_date'] = df.loc[~mask, 'Datetime']\n",
    "df['silo_observation_date'] = pd.to_datetime(df['silo_observation_date']).dt.date\n",
    "\n",
    "# Remove rows of the first and last dates of each site because those days lack some hours\n",
    "first_last_dates = df.groupby('SiteID')['silo_observation_date'].agg(['min', 'max']).reset_index()\n",
    "df = df.merge(first_last_dates, on='SiteID', how='left')\n",
    "df_date_filtered = df[(df['silo_observation_date'] != df['min']) & (df['silo_observation_date'] != df['max'])]\n",
    "df_date_filtered = df_date_filtered.drop(columns=['min', 'max'])\n",
    "\n",
    "# Select only rows with max tempurature of the day\n",
    "df_date_filtered['Day_max_temp'] = df_date_filtered.groupby(['SiteID', 'silo_observation_date'])['Temperature'].transform('max')\n",
    "df_max_temp = df_date_filtered[df_date_filtered['Temperature'] == df_date_filtered['Day_max_temp']]\n",
    "print(\"In-situ day maximum temperature observations:\")\n",
    "print(df_max_temp.head())\n",
    "print('\\n')\n",
    "\n",
    "# Select only rows with min tempurature of the day\n",
    "df_date_filtered['Day_min_temp'] = df_date_filtered.groupby(['SiteID', 'silo_observation_date'])['Temperature'].transform('min')\n",
    "df_min_temp = df_date_filtered[df_date_filtered['Temperature'] == df_date_filtered['Day_min_temp']]\n",
    "print(\"In-situ day minimum temperature observations:\")\n",
    "df_min_temp.head()\n",
    "\n",
    "# -------------------------------------- Investigation code below --------------------------------------\n",
    "# df_max_temp[df_max_temp['Datetime'].dt.hour < 9]\n",
    "\n",
    "# import datetime\n",
    "# df[(df['SiteID'] == 79) & (df['Date'] == datetime.date(2019, 1, 30))]\n",
    "# df[(df['SiteID'] == 90) & (df['Date'] == datetime.date(2019, 2, 19))]  ## Hottest in the morning\n",
    "# df[(df['SiteID'] == 90) & (df['Date'] == datetime.date(2019, 3, 6))]\n",
    "# df[(df['SiteID'] == 142) & (df['Date'] == datetime.date(2019, 3, 27))]\n",
    "# df[(df['SiteID'] == 78) & (df['Date'] == datetime.date(2019, 1, 19))]\n",
    "\n",
    "# df_date_filtered.groupby(['SiteID', 'Date'])['Datetime'].apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "ruJytNXSJ3RT",
    "outputId": "b8b40f73-be93-40d8-afb4-9b8d8c2e4b7f"
   },
   "outputs": [],
   "source": [
    "# Use only one observation per sit per day\n",
    "\n",
    "df_max_temp = df_max_temp.loc[\n",
    "    df_max_temp.groupby(['SiteID', 'silo_observation_date'])['RH'].idxmin()\n",
    "]\n",
    "df_min_temp = df_min_temp.loc[\n",
    "    df_min_temp.groupby(['SiteID', 'silo_observation_date'])['RH'].idxmin()\n",
    "]\n",
    "df_max_temp.head()\n",
    "\n",
    "# Investigating the number of obs per site per day\n",
    "# df_max_temp.groupby(['SiteID', 'silo_observation_date'])['Datetime'].apply(lambda x: x.nunique())\n",
    "# Check the accuracy of the code\n",
    "# import datetime\n",
    "# df_max_temp[(df_max_temp['SiteID'] == 264) & (df_max_temp['silo_observation_date'] == datetime.date(2020, 3, 21))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "ML2LZQCp0Qw8",
    "outputId": "7d057455-04c8-4378-938d-e627fd072fd4"
   },
   "outputs": [],
   "source": [
    "# Fill in df with silo data at the hottest time of the day (max_temp, RH_tmax)\n",
    "\n",
    "# For each row, open silo data csv file one-by-one to get data\n",
    "def get_silo_value(row, column):\n",
    "    file_path = os.path.join(silo_data_dir, f\"silo_data_{row['silo_X']}_{row['silo_Y']}.csv\")\n",
    "    df_silo = pd.read_csv(file_path)\n",
    "\n",
    "    df_silo['Datetime'] = pd.to_datetime(df_silo['YYYY-MM-DD'], format='%Y-%m-%d')\n",
    "    target_date = row['silo_observation_date']\n",
    "    silo_value = df_silo.loc[df_silo['Datetime'].dt.date == target_date, column].values[0]\n",
    "\n",
    "    return silo_value\n",
    "\n",
    "df_max_temp['silo_Temperature'] = df_max_temp.apply(lambda row: get_silo_value(row, 'max_temp'), axis=1)\n",
    "df_max_temp['silo_RH'] = df_max_temp.apply(lambda row: get_silo_value(row, 'rh_tmax'), axis=1)\n",
    "df_max_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "bZDG20zhO1dk",
    "outputId": "50523c16-0a65-4552-a8e6-12f74acf62f9"
   },
   "outputs": [],
   "source": [
    "# Fill in df with silo data at the coldest time of the day (min_temp, RH_tmin)\n",
    "\n",
    "df_min_temp['silo_Temperature'] = df_min_temp.apply(lambda row: get_silo_value(row, 'min_temp'), axis=1)\n",
    "df_min_temp['silo_RH'] = df_min_temp.apply(lambda row: get_silo_value(row, 'rh_tmin'), axis=1)\n",
    "df_min_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "MI3KLC0BRVRn",
    "outputId": "6a4d0fec-b8d5-41a1-cb6e-a5dab611be4b"
   },
   "outputs": [],
   "source": [
    "# Investigate null values. Site 251 is located in the ocean.\n",
    "print(\"df_max_temp length: \", len(df_max_temp))\n",
    "print(\"df_min_temp length: \", len(df_min_temp))\n",
    "df_max_temp[(df_max_temp.isna().any(axis=1)) & (df_max_temp['SiteID'] != 251)]\n",
    "df_min_temp[(df_min_temp.isna().any(axis=1)) & (df_min_temp['SiteID'] != 251)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZaBSFcqP3G3"
   },
   "source": [
    "# Calculating remote VPD from remote temperature and remote relative humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "hpDDwg6tBYPG",
    "outputId": "a6ecd209-bfd6-41ca-bdd2-bffe4020bbd5"
   },
   "outputs": [],
   "source": [
    "# Write a function for deriving VPD from temp and RH\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def calculate_vpd(temp, rh):\n",
    "    if pd.isna(temp) or pd.isna(rh):\n",
    "        return np.nan\n",
    "    es = 0.6108 * math.exp(17.27 * temp / (237.3 + temp))\n",
    "    e = es * rh / 100\n",
    "    vpd = es - e\n",
    "    return vpd\n",
    "\n",
    "df_max_temp['silo_VPD'] = df_max_temp.apply(lambda row: calculate_vpd(row['silo_Temperature'], row['silo_RH']), axis=1)\n",
    "df_min_temp['silo_VPD'] = df_min_temp.apply(lambda row: calculate_vpd(row['silo_Temperature'], row['silo_RH']), axis=1)\n",
    "df_max_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm8xvMkaQEWI"
   },
   "source": [
    "# Save the resulting dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qp9werSMATEH"
   },
   "outputs": [],
   "source": [
    "# Drop helper columns\n",
    "df_max_temp.drop(columns=['Day_max_temp'], inplace=True)\n",
    "df_min_temp.drop(columns=['Day_max_temp', 'Day_min_temp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HURGOZDVwjs"
   },
   "outputs": [],
   "source": [
    "# save df\n",
    "df_max_temp.to_csv(os.path.join(\"..\", \"..\", \"output\", \"csv\", max_temp_output_file_name), index=False)\n",
    "df_min_temp.to_csv(os.path.join(\"..\", \"..\", \"output\", \"csv\", min_temp_output_file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMIYIUmL8lyMo8BTvn/YeAu",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
