{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n",
    "\n",
    "This script fills in slope, relief, aspect, vegetation cover data into in-situ observations. It can only be used to filled in vegetation cover value that are saved individually for each site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EVlEv6AIXRc"
   },
   "outputs": [],
   "source": [
    "# Set variables\n",
    "working_dir = '../..'  # This repository's root directory\n",
    "insitu_data_path = 'Data/pcs/pcs.csv'\n",
    "output_dir_path = 'output/csv/in-situ_topography_pcs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_X5h350Hduv",
    "outputId": "2b26f7d6-a07e-4569-a60c-dab2a299ba5c"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from pyproj import Transformer\n",
    "from rasterio.merge import merge\n",
    "from rasterio.transform import rowcol\n",
    "from rasterio.warp import transform\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "sys.path.append(working_dir)\n",
    "from Utils.barra2 import *\n",
    "from Utils.vpd import calculate_vpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPWnv-rha6X9"
   },
   "outputs": [],
   "source": [
    "# Generate output directory\n",
    "\n",
    "output_dir = os.path.join(working_dir, 'output', 'csv')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "df = pd.read_csv(os.path.join(working_dir, insitu_data_path))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sites_df to fill in slope, aspect, and relief\n",
    "\n",
    "sites_df = df[['SiteID', 'X', 'Y']].drop_duplicates(ignore_index=True)\n",
    "sites_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRxLZ1NxSaEp"
   },
   "source": [
    "## Fill in slope, aspect, and relief of each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGKJ6x3ZJKTy"
   },
   "outputs": [],
   "source": [
    "# Add slope, aspect, and relief data tp sites_df\n",
    "\n",
    "transformer = Transformer.from_crs('EPSG:4326', \"EPSG:28355\", always_xy=True)\n",
    "\n",
    "\n",
    "def get_value_from_latlon(data, trans, x, y):\n",
    "    # Find corresponding row and column with latlon\n",
    "    x_proj, y_proj = transformer.transform([x], [y])\n",
    "    row, col = rowcol(trans, x_proj, y_proj)\n",
    "\n",
    "    try:\n",
    "        return data[row, col][0]\n",
    "    except:\n",
    "        print(\n",
    "            f\"There is a row with lon {x}, lat {y} outside tif files' area. The value is set to np.nan\"\n",
    "        )\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def add_data_to_df(df, property, tif_files_keyword=\"\"):\n",
    "    # Find all related tif files\n",
    "    files = glob.glob(os.path.join(working_dir, 'output', 'tif', f'*{property}.tif'))\n",
    "    print(f\"There are {len(files)} {property} files: {files}\")\n",
    "\n",
    "    if tif_files_keyword == \"\":\n",
    "        # Merge all tif files\n",
    "        src_files_to_mosaic = [rasterio.open(f) for f in files]\n",
    "        mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "        data = mosaic[0]\n",
    "    else:\n",
    "        data_path = [file for file in files if tif_files_keyword in file][0]\n",
    "        with rasterio.open(data_path) as src:\n",
    "            data = src.read(1)\n",
    "            out_trans = src.transform\n",
    "\n",
    "    # Add data to df\n",
    "    df[property] = df.apply(\n",
    "        lambda row: get_value_from_latlon(data, out_trans, row['X'], row['Y']), axis=1\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "SgWxjt8aEnLW",
    "outputId": "d590def5-2dc1-4ff0-a9d5-6305af4dc919"
   },
   "outputs": [],
   "source": [
    "sites_df = add_data_to_df(sites_df, 'slope', tif_files_keyword=\"pcs\")\n",
    "sites_df = add_data_to_df(sites_df, 'aspect', tif_files_keyword=\"pcs\")\n",
    "sites_df = add_data_to_df(sites_df, 'relief', tif_files_keyword=\"pcs\")\n",
    "sites_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate missing values\n",
    "sites_with_nans_df = sites_df[\n",
    "    (sites_df['slope'].isna()) | (sites_df['aspect'].isna()) | (sites_df['relief'].isna())\n",
    "]\n",
    "sites_with_nans_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in vegetation cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find X, Y in DEA crs for each site\n",
    "\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32754\", always_xy=True)\n",
    "sites_df['dea_x'], sites_df['dea_y'] = transformer.transform(\n",
    "    sites_df['X'].values, sites_df['Y'].values\n",
    ")\n",
    "sites_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read veg cover NetCFD of each site and put it in sites_df\n",
    "\n",
    "\n",
    "def get_veg_ds(row):\n",
    "    site_id = row['SiteID']\n",
    "    veg_cover_data_path = os.path.join(working_dir, \"Data\", \"veg_cover\", f\"veg_cover_{site_id}.nc\")\n",
    "    veg_ds = xr.open_dataset(veg_cover_data_path)\n",
    "\n",
    "    return veg_ds['veg_cover']\n",
    "\n",
    "\n",
    "sites_df['veg_cover_point_series'] = sites_df.apply(lambda row: get_veg_ds(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ss3NXUTHXYlx",
    "outputId": "34fa6637-aa97-44da-ca5b-a2f765314e6a"
   },
   "outputs": [],
   "source": [
    "# Add the site data to df\n",
    "\n",
    "df = df.merge(\n",
    "    sites_df[[\"SiteID\", \"slope\", \"aspect\", \"relief\", 'dea_x', 'dea_y', 'veg_cover_point_series']],\n",
    "    on=['SiteID'],\n",
    "    how='left',\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNSUuwdkIBFQ"
   },
   "outputs": [],
   "source": [
    "# Fill in veg cover in df row by row\n",
    "\n",
    "\n",
    "def get_veg_cover(row):\n",
    "    x = row['dea_x']\n",
    "    y = row['dea_y']\n",
    "    t = row['UTC_Datetime']\n",
    "    point_series = row['veg_cover_point_series']\n",
    "\n",
    "    # Drop NaNs\n",
    "    valid_series = point_series.dropna(dim='time')\n",
    "\n",
    "    if valid_series.sizes['time'] == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Find the nearest time, within 30 days, with non-NaN veg_cover\n",
    "    time_deltas = np.abs(valid_series['time'] - np.datetime64(t))\n",
    "    if time_deltas.min() > np.timedelta64(30, 'D'):\n",
    "        print(\"min time_deltas: \", time_deltas.min() / np.timedelta64(1, 'D'))\n",
    "        return np.nan\n",
    "    nearest_idx = time_deltas.argmin().item()\n",
    "    veg_cover = valid_series.isel(time=nearest_idx).item()\n",
    "\n",
    "    return veg_cover if veg_cover < 100 else 100\n",
    "\n",
    "\n",
    "df['veg_cover'] = df.progress_apply(get_veg_cover, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQSVyLZFSHYB"
   },
   "source": [
    "# Save df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sw6bn10MNMzU"
   },
   "outputs": [],
   "source": [
    "# save df\n",
    "df.drop(columns=['dea_x', 'dea_y', 'veg_cover_point_series'], inplace=True)\n",
    "df.to_csv(os.path.join(output_dir, output_dir_path), index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN8YVYex8KvTne1GXcKYa0k",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
